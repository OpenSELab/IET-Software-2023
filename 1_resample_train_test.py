# -*- coding: utf-8 -*-
"""1-resample_train_test

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tcf-JbuOlYK88jugFjIcdxoCqJoblgcd
"""

# Commented out IPython magic to ensure Python compatibility.
import scipy.io.arff
import pandas as pd
import numpy as np
from sklearn.utils import resample # for Bootstrap sampling
import shutil
import os



from numpy import array


#Import graphical plotting libraries
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

#Import resampling and modeling algorithms

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier


from sklearn.model_selection import train_test_split

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import matthews_corrcoef
import warnings

warnings.filterwarnings("ignore")

# click load google drive
rootpath = "/content/drive/MyDrive/Colab Notebooks/1/"

datasets_original = "datasets-original/"
datasets_discretize = "datasets-discretize/"
datasets_log = "datasets-log/"
datasets_minmax = "datasets-min-max/"
datasets_standardize = "datasets-standardize/"

"""
AEEEM = ["EQ", "JDT", "LC", "ML", "PDE"]
ReLink = ["Zxing", "Apache", "Safe"]
Columba = ["columba", "eclipse", "scarab"] # remove because has data < 0
Promise = ["ant-1.3", "ant-1.4", "ant-1.5", "ant-1.6", "ant-1.7",
           "camel-1.0", "camel-1.2", "camel-1.4", "camel-1.6",
           "ivy-1.1", "ivy-1.4", "ivy-2.0",
           "jedit-3.2", "jedit-4.0", "jedit-4.1", "jedit-4.2",
           "log4j-1.0", "log4j-1.1", "log4j-1.2",
           "lucene-2.0", "lucene-2.2", "lucene-2.4",
           "poi-1.5", "poi-2.0", "poi-2.5", "poi-3.0",
           "xalan-2.4", "xalan-2.5", "xalan-2.6",
           "xerces-1.2", "xerces-1.3", "xerces-1.4"]
"""
AEEEM = ["EQ"]
ReLink = ["Zxing", "Apache", "Safe"]
Promise = [ "camel-1.2", "ivy-1.1", "jedit-3.2", "log4j-1.1", "lucene-2.0", "lucene-2.2", "lucene-2.4",
        "poi-1.5", "poi-2.5", "poi-3.0", "xalan-2.5", "xalan-2.6"]

ARFF = "ARFF/"
CSV = "CSV/"

BOOTSTRAP = "BOOTSTRAP/"

# CLS = [RandomForestClassifier(),LogisticRegression(),GaussianNB(),DecisionTreeClassifier(),KNeighborsClassifier(),MLPClassifier()]
CLS = [RandomForestClassifier(random_state=0),LogisticRegression(random_state=0),GaussianNB(),DecisionTreeClassifier(random_state=0),KNeighborsClassifier(),MLPClassifier(random_state=0)]

# some data sets imbanlance so we exclude it because these classifier have precision recall and f1 = 0  so we select 30-70% percent of defective

def setDir(filepath):
    #if filepath not exist then create  ！

    if not os.path.exists(filepath):
        pass
    else:
        shutil.rmtree(filepath,ignore_errors=True)

# Lets configure Bootstrap
sample_times = 25  #No. of bootstrap samples to be repeated (created) seed is 0-24
# Lets run Bootstrap
# change the datasets name in turn

readfilepath = rootpath + datasets_standardize + ARFF

outfilepath = rootpath + datasets_standardize

performance_list = list()
for i in range(len(ReLink)):

  readfile = readfilepath + "ReLink/" + ReLink[i] + ".arff"
  data,meta = scipy.io.arff.loadarff(readfile) # NOTE: ReLink original has bug{Y,N}->error  correct is bug {Y,N}

  df = pd.DataFrame(data)

  # bug has a b'Y' and b'N'
  df["bug"] = (df["bug"]== b"Y").astype(int)  # then bug into N->0 Y->1 !!!

  print(performance_list)

  for j in range(len(CLS)):

    #accuracy_list = list()
    #precision_list = list()
    #recall_list = list()
    #f1_list = list()
    #auc_list = list()
    #mcc_list = list()

    # Bootstrap
    for k in range(sample_times):

      #prepare train & test sets
      #Sampling with replacement..whichever is not used in training data will be used in test data
      train = resample(df, random_state = k)

      #picking rest of the data not considered in training sample test = df - train
      test = pd.concat([df, train, train]).drop_duplicates(keep = False)

      #print(train)
      #print(test)

      train = np.array(train)
      test = np.array(test)

      #fit model
      model = CLS[j] # can change max_iter=1000
      model.fit(train[:,:-1], train[:,-1]) #model.fit(X_train,y_train) i.e model.fit(train set, train label as it is a classifier)
      #evaluate model
      predictions = model.predict(test[:,:-1]) #model.predict(X_test)


      accuracy = accuracy_score(test[:,-1], predictions) #accuracy_score(y_test, y_pred)
      precision = precision_score(test[:,-1], predictions)
      recall = recall_score(test[:,-1], predictions)
      f1 = f1_score(test[:,-1], predictions)
      auc = roc_auc_score(test[:,-1], predictions)
      mcc = matthews_corrcoef(test[:,-1], predictions)

      performance_list.append((ReLink[i],str(CLS[j])+str(k),accuracy,precision,recall,f1,auc,mcc))

      #caution, overall accuracy score can mislead when classes are imbalanced
      #accuracy_list.append(accuracy)
      #precision_list.append(precision)
      #recall_list.append(recall)
      #f1_list.append(f1)
      #auc_list.append(auc)
      #mcc_list.append(mcc)

print("end")
print(performance_list)
# save as csv files
out_file = outfilepath + "ReLink-performance.csv"
setDir(out_file)
out_file_performance = pd.DataFrame(performance_list,columns=["project","cls_boot","accuracy","precision","recall","f1","auc","mcc"])

out_file_performance.to_csv(out_file,index=False,columns=["project","cls_boot","accuracy","precision","recall","f1","auc","mcc"])








# performance end

"""**下面是草稿**"""

#Lets configure Bootstrap
n_iterations = 25  #No. of bootstrap samples to be repeated (created)
#Lets run Bootstrap

for i in range(n_iterations):
    #prepare train & test sets
    #Sampling with replacement..whichever is not used in training data will be used in test data
    train = resample(df,random_state=i)

    #picking rest of the data not considered in training sample test = df - train
    test = pd.concat([df, train, train]).drop_duplicates(keep=False)








    # save as csv files
    out_file_train = outfilepath + AEEEM[i] + "-train-" + str(k) + ".csv"
    out_file_test = outfilepath + AEEEM[i] + "-test-" + str(k) + ".csv"

    output_train = pd.DataFrame(train)
    output_test = pd.DataFrame(test)
    output_train.to_csv(out_file_train,index=False)
    output_test.to_csv(out_file_test,index=False)

# bootstrap finished but ReLink original-datasets cannot resample because of the files in it bug{Y,N}->error miss a space, crrect is bug {Y,N}