# -*- coding: utf-8 -*-
"""1-permutation_different_metric_rank_diff_all_Precision

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yO7xDwqyrwq5nWzKxnLUfR0O2XSqcQSb
"""

import scipy.io.arff
import pandas as pd
import numpy as np
from sklearn.utils import resample # for Bootstrap sampling
import shutil
import os

from numpy import array

#Import resampling and modeling algorithms

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import matthews_corrcoef

import warnings

warnings.filterwarnings("ignore")

# click load google drive
rootpath = "/content/drive/MyDrive/Colab Notebooks/1/"

datasets_original = "datasets-original/"
datasets_discretize = "datasets-discretize/"
datasets_log = "datasets-log/"
datasets_minmax = "datasets-min-max/"
datasets_standardize = "datasets-standardize/"

AEEEM = ["EQ"]
ReLink = ["Zxing", "Apache", "Safe"]
Promise = [ "camel-1.2", "ivy-1.1", "jedit-3.2", "log4j-1.1", "lucene-2.0", "lucene-2.2", "lucene-2.4",
        "poi-1.5", "poi-2.5", "poi-3.0", "xalan-2.5", "xalan-2.6"]

ARFF = "ARFF/"
CSV = "CSV/"

BOOTSTRAP = "BOOTSTRAP/"


# some data sets imbanlance so we exclude it because these classifier have precision recall and f1 = 0  so we select 30-70% percent of defective

data_o_Promise = pd.DataFrame(pd.read_csv(rootpath + datasets_original + "Promise-permutation-test-precision-rank.csv"))

data_o_ReLink = pd.DataFrame(pd.read_csv(rootpath + datasets_original + "ReLink-permutation-test-precision-rank.csv"))

data_o_AEEEM = pd.DataFrame(pd.read_csv(rootpath + datasets_original + "AEEEM-permutation-test-precision-rank.csv"))

data_log_Promise = pd.DataFrame(pd.read_csv(rootpath + datasets_log + "Promise-permutation-test-precision-rank.csv"))

data_log_ReLink = pd.DataFrame(pd.read_csv(rootpath + datasets_log + "ReLink-permutation-test-precision-rank.csv"))

data_log_AEEEM = pd.DataFrame(pd.read_csv(rootpath + datasets_log + "AEEEM-permutation-test-precision-rank.csv"))


data_min_Promise = pd.DataFrame(pd.read_csv(rootpath + datasets_minmax + "Promise-permutation-test-precision-rank.csv"))

data_min_ReLink = pd.DataFrame(pd.read_csv(rootpath + datasets_minmax + "ReLink-permutation-test-precision-rank.csv"))

data_min_AEEEM = pd.DataFrame(pd.read_csv(rootpath + datasets_minmax + "AEEEM-permutation-test-precision-rank.csv"))

data_sta_Promise = pd.DataFrame(pd.read_csv(rootpath + datasets_standardize + "Promise-permutation-test-precision-rank.csv"))

data_sta_ReLink = pd.DataFrame(pd.read_csv(rootpath + datasets_standardize + "ReLink-permutation-test-precision-rank.csv"))

data_sta_AEEEM = pd.DataFrame(pd.read_csv(rootpath + datasets_standardize + "AEEEM-permutation-test-precision-rank.csv"))


'''

print(data_o_Promise.shape)
print(data_log_Promise.shape)
print(data_o_Promise.shape[0])
print(data_log_Promise.shape[1])
print(data_o_Promise.index)

'''


O = [data_o_Promise, data_o_ReLink, data_o_AEEEM]
L = [data_log_Promise, data_log_ReLink, data_log_AEEEM]
M = [data_min_Promise, data_min_ReLink, data_min_AEEEM]
S = [data_sta_Promise, data_sta_ReLink, data_sta_AEEEM]

L_O_diff_1_list = []
L_O_diff_2_list = []
L_O_diff_3_list = []
L_O_diff_4_list = []
L_O_diff_5_list = []

M_O_diff_1_list = []
M_O_diff_2_list = []
M_O_diff_3_list = []
M_O_diff_4_list = []
M_O_diff_5_list = []

S_O_diff_1_list = []
S_O_diff_2_list = []
S_O_diff_3_list = []
S_O_diff_4_list = []
S_O_diff_5_list = []



# 3个数据集
for k in range(len(O)):
  # 多少行
  for i in range(O[k].shape[0]):
    # 多少列 每一列的值
    for j in range(O[k].shape[1]):

      if(O[k].loc[i].values[j] == 1):  # =1即1-rank =2即2-rank

        #print(i,j)
        attr_1 = list(O[k])[j]

        L_new_rank_1 = L[k].loc[i,attr_1]
        M_new_rank_1 = M[k].loc[i,attr_1]
        S_new_rank_1 = S[k].loc[i,attr_1]

        L_diff_1 = abs(L_new_rank_1 - 1)  # =1 表示之前排名1 的 偏移量 =2 =3
        M_diff_1 = abs(M_new_rank_1 - 1)  # =1 表示之前排名1 的 偏移量 =2 =3
        S_diff_1 = abs(S_new_rank_1 - 1)  # =1 表示之前排名1 的 偏移量 =2 =3

        L_O_diff_1_list.append(L_diff_1)
        M_O_diff_1_list.append(M_diff_1)
        S_O_diff_1_list.append(S_diff_1)

        #print(data_log_Promise.loc[i,attr])
        #print(list(data_o_Promise)[j])
        #print(data_o_Promise.loc[i].values[j])


      if(O[k].loc[i].values[j] == 2):

        #print(i,j)
        attr_2 = list(O[k])[j]

        L_new_rank_2 = L[k].loc[i,attr_2]
        M_new_rank_2 = M[k].loc[i,attr_2]
        S_new_rank_2 = S[k].loc[i,attr_2]

        L_diff_2 = abs(L_new_rank_2 - 2)
        M_diff_2 = abs(M_new_rank_2 - 2)
        S_diff_2 = abs(S_new_rank_2 - 2)

        L_O_diff_2_list.append(L_diff_2)
        M_O_diff_2_list.append(M_diff_2)
        S_O_diff_2_list.append(S_diff_2)

      if(O[k].loc[i].values[j] == 3):

        #print(i,j)
        attr_3 = list(O[k])[j]

        L_new_rank_3 = L[k].loc[i,attr_3]
        M_new_rank_3 = M[k].loc[i,attr_3]
        S_new_rank_3 = S[k].loc[i,attr_3]

        L_diff_3 = abs(L_new_rank_3 - 3)
        M_diff_3 = abs(M_new_rank_3 - 3)
        S_diff_3 = abs(S_new_rank_3 - 3)

        L_O_diff_3_list.append(L_diff_3)
        M_O_diff_3_list.append(M_diff_3)
        S_O_diff_3_list.append(S_diff_3)

      if(O[k].loc[i].values[j] == 4):

        #print(i,j)
        attr_4 = list(O[k])[j]

        L_new_rank_4 = L[k].loc[i,attr_4]
        M_new_rank_4 = M[k].loc[i,attr_4]
        S_new_rank_4 = S[k].loc[i,attr_4]

        L_diff_4 = abs(L_new_rank_4 - 4)
        M_diff_4 = abs(M_new_rank_4 - 4)
        S_diff_4 = abs(S_new_rank_4 - 4)

        L_O_diff_4_list.append(L_diff_4)
        M_O_diff_4_list.append(M_diff_4)
        S_O_diff_4_list.append(S_diff_4)

      if(O[k].loc[i].values[j] == 5):

        #print(i,j)
        attr_5 = list(O[k])[j]

        L_new_rank_5 = L[k].loc[i,attr_5]
        M_new_rank_5 = M[k].loc[i,attr_5]
        S_new_rank_5 = S[k].loc[i,attr_5]

        L_diff_5 = abs(L_new_rank_5 - 5)
        M_diff_5 = abs(M_new_rank_5 - 5)
        S_diff_5 = abs(S_new_rank_5 - 5)

        L_O_diff_5_list.append(L_diff_5)
        M_O_diff_5_list.append(M_diff_5)
        S_O_diff_5_list.append(S_diff_5)


print("L_O_diff_1_list-------------------------------")
print(L_O_diff_1_list)
print(len(L_O_diff_1_list))  # 为什么不是1800？因为有某个行存在两个1 所以秩差就会有多个值；
print("M_O_diff_1_list-------------------------------")
print(M_O_diff_1_list)
print(len(M_O_diff_1_list))  # 为什么不是1800？因为有某个行存在两个1 所以秩差就会有多个值；
print("S_O_diff_1_list-------------------------------")
print(S_O_diff_1_list)
print(len(S_O_diff_1_list))  # 为什么不是1800？因为有某个行存在两个1 所以秩差就会有多个值；

print("L_O_diff_2_list-------------------------------")
print(L_O_diff_2_list)
print(len(L_O_diff_2_list))  # 为什么不是2800？因为有某个行存在两个2 所以秩差就会有多个值；
print("M_O_diff_2_list-------------------------------")
print(M_O_diff_2_list)
print(len(M_O_diff_2_list))  # 为什么不是2800？因为有某个行存在两个2 所以秩差就会有多个值；
print("S_O_diff_2_list-------------------------------")
print(S_O_diff_2_list)
print(len(S_O_diff_2_list))  # 为什么不是2800？因为有某个行存在两个2 所以秩差就会有多个值；

print("L_O_diff_3_list-------------------------------")
print(L_O_diff_3_list)
print(len(L_O_diff_3_list))  # 为什么不是3800？因为有某个行存在两个3 所以秩差就会有多个值；
print("M_O_diff_3_list-------------------------------")
print(M_O_diff_3_list)
print(len(M_O_diff_3_list))  # 为什么不是3800？因为有某个行存在两个3 所以秩差就会有多个值；
print("S_O_diff_3_list-------------------------------")
print(S_O_diff_3_list)
print(len(S_O_diff_3_list))  # 为什么不是3800？因为有某个行存在两个3 所以秩差就会有多个值；

print("L_O_diff_4_list-------------------------------")
print(L_O_diff_4_list)
print(len(L_O_diff_4_list))  # 为什么不是4800？因为有某个行存在两个4 所以秩差就会有多个值；
print("M_O_diff_4_list-------------------------------")
print(M_O_diff_4_list)
print(len(M_O_diff_4_list))  # 为什么不是4800？因为有某个行存在两个4 所以秩差就会有多个值；
print("S_O_diff_4_list-------------------------------")
print(S_O_diff_4_list)
print(len(S_O_diff_4_list))  # 为什么不是4800？因为有某个行存在两个4 所以秩差就会有多个值；

print("L_O_diff_5_list-------------------------------")
print(L_O_diff_5_list)
print(len(L_O_diff_5_list))  # 为什么不是5800？因为有某个行存在两个5 所以秩差就会有多个值；
print("M_O_diff_5_list-------------------------------")
print(M_O_diff_5_list)
print(len(M_O_diff_5_list))  # 为什么不是5800？因为有某个行存在两个5 所以秩差就会有多个值；
print("S_O_diff_5_list-------------------------------")
print(S_O_diff_5_list)
print(len(S_O_diff_5_list))  # 为什么不是5800？因为有某个行存在两个5 所以秩差就会有多个值；


# iterrows itertuples
#for row_o in data_o_Promise.itertuples():
  #print(getattr(row_o,"Index"))


#df = pd.DataFrame(data)

#df_features = list(df)

#print(df_features)

#print(df_features[2:])

# AEEEM 150行63列 1个数据集 6个分类器 25次采样 150次实验 61列属性 2列自己加的标记 63列属性
# Promise 1800行22列 12个数据集 6个分类器 25次采样 1800次实验
# ReLink 450行28列 3个数据集 6个分类器 25次采样 450次实验
#print(df.shape)


#print(list(df_rank))

#  计算结束

from collections import Counter


count_L_O_1 = Counter(L_O_diff_1_list)
count_L_O_2 = Counter(L_O_diff_2_list)
count_L_O_3 = Counter(L_O_diff_3_list)
count_L_O_4 = Counter(L_O_diff_4_list)
count_L_O_5 = Counter(L_O_diff_5_list)

count_M_O_1 = Counter(M_O_diff_1_list)
count_M_O_2 = Counter(M_O_diff_2_list)
count_M_O_3 = Counter(M_O_diff_3_list)
count_M_O_4 = Counter(M_O_diff_4_list)
count_M_O_5 = Counter(M_O_diff_5_list)

count_S_O_1 = Counter(S_O_diff_1_list)
count_S_O_2 = Counter(S_O_diff_2_list)
count_S_O_3 = Counter(S_O_diff_3_list)
count_S_O_4 = Counter(S_O_diff_4_list)
count_S_O_5 = Counter(S_O_diff_5_list)

count_L_O_diff_1_pd = pd.DataFrame(count_L_O_1.items(),columns=['label', 'counts'])
count_L_O_diff_1_pd['probability']=count_L_O_diff_1_pd['counts']/len(L_O_diff_1_list)
count_L_O_diff_2_pd = pd.DataFrame(count_L_O_2.items(),columns=['label', 'counts'])
count_L_O_diff_2_pd['probability']=count_L_O_diff_2_pd['counts']/len(L_O_diff_2_list)
count_L_O_diff_3_pd = pd.DataFrame(count_L_O_3.items(),columns=['label', 'counts'])
count_L_O_diff_3_pd['probability']=count_L_O_diff_3_pd['counts']/len(L_O_diff_3_list)
count_L_O_diff_4_pd = pd.DataFrame(count_L_O_4.items(),columns=['label', 'counts'])
count_L_O_diff_4_pd['probability']=count_L_O_diff_4_pd['counts']/len(L_O_diff_4_list)
count_L_O_diff_5_pd = pd.DataFrame(count_L_O_5.items(),columns=['label', 'counts'])
count_L_O_diff_5_pd['probability']=count_L_O_diff_5_pd['counts']/len(L_O_diff_5_list)

count_M_O_diff_1_pd = pd.DataFrame(count_M_O_1.items(),columns=['label', 'counts'])
count_M_O_diff_1_pd['probability']=count_M_O_diff_1_pd['counts']/len(M_O_diff_1_list)
count_M_O_diff_2_pd = pd.DataFrame(count_M_O_2.items(),columns=['label', 'counts'])
count_M_O_diff_2_pd['probability']=count_M_O_diff_2_pd['counts']/len(M_O_diff_2_list)
count_M_O_diff_3_pd = pd.DataFrame(count_M_O_3.items(),columns=['label', 'counts'])
count_M_O_diff_3_pd['probability']=count_M_O_diff_3_pd['counts']/len(M_O_diff_3_list)
count_M_O_diff_4_pd = pd.DataFrame(count_M_O_4.items(),columns=['label', 'counts'])
count_M_O_diff_4_pd['probability']=count_M_O_diff_4_pd['counts']/len(M_O_diff_4_list)
count_M_O_diff_5_pd = pd.DataFrame(count_M_O_5.items(),columns=['label', 'counts'])
count_M_O_diff_5_pd['probability']=count_M_O_diff_5_pd['counts']/len(M_O_diff_5_list)

count_S_O_diff_1_pd = pd.DataFrame(count_S_O_1.items(),columns=['label', 'counts'])
count_S_O_diff_1_pd['probability']=count_S_O_diff_1_pd['counts']/len(S_O_diff_1_list)
count_S_O_diff_2_pd = pd.DataFrame(count_S_O_2.items(),columns=['label', 'counts'])
count_S_O_diff_2_pd['probability']=count_S_O_diff_2_pd['counts']/len(S_O_diff_2_list)
count_S_O_diff_3_pd = pd.DataFrame(count_S_O_3.items(),columns=['label', 'counts'])
count_S_O_diff_3_pd['probability']=count_S_O_diff_3_pd['counts']/len(S_O_diff_3_list)
count_S_O_diff_4_pd = pd.DataFrame(count_S_O_4.items(),columns=['label', 'counts'])
count_S_O_diff_4_pd['probability']=count_S_O_diff_4_pd['counts']/len(S_O_diff_4_list)
count_S_O_diff_5_pd = pd.DataFrame(count_S_O_5.items(),columns=['label', 'counts'])
count_S_O_diff_5_pd['probability']=count_S_O_diff_5_pd['counts']/len(S_O_diff_5_list)



print("L-O ---------------------")
print(count_L_O_1)
print(count_L_O_diff_1_pd)
print(count_L_O_2)
print(count_L_O_diff_2_pd)
print(count_L_O_3)
print(count_L_O_diff_3_pd)
print(count_L_O_4)
print(count_L_O_diff_4_pd)
print(count_L_O_5)
print(count_L_O_diff_5_pd)


print("M-O ---------------------")
print(count_M_O_1)
print(count_M_O_diff_1_pd)
print(count_M_O_2)
print(count_M_O_diff_2_pd)
print(count_M_O_3)
print(count_M_O_diff_3_pd)
print(count_M_O_4)
print(count_M_O_diff_4_pd)
print(count_M_O_5)
print(count_M_O_diff_5_pd)


print("S-O ---------------------")
print(count_S_O_1)
print(count_S_O_diff_1_pd)
print(count_S_O_2)
print(count_S_O_diff_2_pd)
print(count_S_O_3)
print(count_S_O_diff_3_pd)
print(count_S_O_4)
print(count_S_O_diff_4_pd)
print(count_S_O_5)
print(count_S_O_diff_5_pd)

# 重新设置表格


def newdatatable(pd_old,classname):
  prob_0 = float(pd_old['probability'].loc[pd_old["label"]==0.0])
  prob_1 = float(pd_old['probability'].loc[pd_old["label"]==1.0])
  prob_2 = float(pd_old['probability'].loc[pd_old["label"]==2.0])
  prob_other = 1 - prob_0 - prob_1 - prob_2
  pd_new = pd.DataFrame([['0',prob_0,classname],['1',prob_1,classname],['2',prob_2,classname],['other',prob_other,classname]],columns=['label','probability','class'])
  return pd_new

count_L_O_diff_1_pd_new = newdatatable(count_L_O_diff_1_pd,'Log')
count_L_O_diff_2_pd_new = newdatatable(count_L_O_diff_2_pd,'Log')
count_L_O_diff_3_pd_new = newdatatable(count_L_O_diff_3_pd,'Log')
count_L_O_diff_4_pd_new = newdatatable(count_L_O_diff_4_pd,'Log')
count_L_O_diff_5_pd_new = newdatatable(count_L_O_diff_5_pd,'Log')

count_M_O_diff_1_pd_new = newdatatable(count_M_O_diff_1_pd,'Minmax')
count_M_O_diff_2_pd_new = newdatatable(count_M_O_diff_2_pd,'Minmax')
count_M_O_diff_3_pd_new = newdatatable(count_M_O_diff_3_pd,'Minmax')
count_M_O_diff_4_pd_new = newdatatable(count_M_O_diff_4_pd,'Minmax')
count_M_O_diff_5_pd_new = newdatatable(count_M_O_diff_5_pd,'Minmax')

count_S_O_diff_1_pd_new = newdatatable(count_S_O_diff_1_pd,'Sta')
count_S_O_diff_2_pd_new = newdatatable(count_S_O_diff_2_pd,'Sta')
count_S_O_diff_3_pd_new = newdatatable(count_S_O_diff_3_pd,'Sta')
count_S_O_diff_4_pd_new = newdatatable(count_S_O_diff_4_pd,'Sta')
count_S_O_diff_5_pd_new = newdatatable(count_S_O_diff_5_pd,'Sta')

print("重新设置表格数据的概率 增加other列表明差异超过2的概率 L-O-1---------")
print(count_L_O_diff_1_pd_new)
print("重新设置表格数据的概率 增加other列表明差异超过2的概率 L-O-2---------")
print(count_L_O_diff_2_pd_new)
print("重新设置表格数据的概率 增加other列表明差异超过2的概率 L-O-3---------")
print(count_L_O_diff_3_pd_new)
print("重新设置表格数据的概率 增加other列表明差异超过2的概率 L-O-4---------")
print(count_L_O_diff_4_pd_new)
print("重新设置表格数据的概率 增加other列表明差异超过2的概率 L-O-5---------")
print(count_L_O_diff_5_pd_new)


pd_1_new = pd.concat([count_L_O_diff_1_pd_new,count_M_O_diff_1_pd_new,count_S_O_diff_1_pd_new],axis=0)  # 纵向合并
pd_2_new = pd.concat([count_L_O_diff_2_pd_new,count_M_O_diff_2_pd_new,count_S_O_diff_2_pd_new],axis=0)  # 纵向合并
pd_3_new = pd.concat([count_L_O_diff_3_pd_new,count_M_O_diff_3_pd_new,count_S_O_diff_3_pd_new],axis=0)  # 纵向合并
pd_4_new = pd.concat([count_L_O_diff_4_pd_new,count_M_O_diff_4_pd_new,count_S_O_diff_4_pd_new],axis=0)  # 纵向合并
pd_5_new = pd.concat([count_L_O_diff_5_pd_new,count_M_O_diff_5_pd_new,count_S_O_diff_5_pd_new],axis=0)  # 纵向合并

print("合并后分类显示 1 rank -------------")
print(pd_1_new)
print("合并后分类显示 2 rank -------------")
print(pd_2_new)
print("合并后分类显示 3 rank -------------")
print(pd_3_new)
print("合并后分类显示 4 rank -------------")
print(pd_4_new)
print("合并后分类显示 5 rank -------------")
print(pd_5_new)

"""**作图**"""

#作图统计 用的是这个！！！！！！！！！！！！！！！！！！

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt

with sns.axes_style('darkgrid'):
  fig, axes = plt.subplots(1, 5, figsize=(20, 2), sharey=True,  dpi=350) # sharey=True ,sharex=True, dpi=350
  fig.subplots_adjust(wspace=0.010,hspace=0.050)



  axes[0].set_title( "1st Rank Difference",loc='center'  )
  axes[1].set_title( "2nd Rank Difference",loc='center'  )
  axes[2].set_title( "3rd Rank Difference",loc='center'  )
  axes[3].set_title( "4th Rank Difference",loc='center'  )
  axes[4].set_title( "5th Rank Difference",loc='center'  )

  # color='darkblue' color='darkorange' color='darkgreen'

  sns.barplot(x='label',y='probability', hue='class', data=pd_1_new, palette=['darkblue','darkorange','darkgreen'], saturation=2, ax=axes[0]).legend_.remove()

  axes[0].set_ylabel("Ratio")
  axes[0].set_xlabel("")
  axes[0].set_yticks([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])


  sns.barplot(x='label',y='probability', hue='class', data=pd_2_new, palette=['darkblue','darkorange','darkgreen'], saturation=2, ax=axes[1]).legend_.remove()

  axes[1].set_ylabel("")
  axes[1].set_xlabel("")

  sns.barplot(x='label',y='probability', hue='class', data=pd_3_new, palette=['darkblue','darkorange','darkgreen'], saturation=2, ax=axes[2]).legend_.remove()
  axes[2].set_ylabel("")
  axes[2].set_xlabel("")

  sns.barplot(x='label',y='probability', hue='class', data=pd_4_new, palette=['darkblue','darkorange','darkgreen'], saturation=2, ax=axes[3]).legend_.remove()
  axes[3].set_ylabel("")
  axes[3].set_xlabel("")

  sns.barplot(x='label',y='probability', hue='class', data=pd_5_new, palette=['darkblue','darkorange','darkgreen'], saturation=2, ax=axes[4]).legend_.remove()
  axes[4].set_ylabel("")
  axes[4].set_xlabel("")

#作图统计 作图用原始的数据列表

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt



with sns.axes_style('darkgrid'):
  fig, axes = plt.subplots(3, 5, figsize=(12, 6), dpi=350) # sharey=True ,sharex=True, dpi=350
  #fig.subplots_adjust(wspace=0.010,hspace=0.050)



  axes[0][0].set_title( "1st rank difference",loc='center'  )
  axes[0][1].set_title( "2nd rank difference",loc='center'  )
  axes[0][2].set_title( "3rd rank difference",loc='center'  )
  axes[0][3].set_title( "4th rank difference",loc='center'  )
  axes[0][4].set_title( "5th rank difference",loc='center'  )

  axes[0][0].set_xticklabels( "Log")
  axes[1][0].set_xticklabels( "Log")

  sns.barplot(x='label',y='probability', data=count_L_O_diff_1_pd_new, ax=axes[0][0])
  sns.barplot(x='label',y='probability', data=count_L_O_diff_2_pd_new, ax=axes[0][1])
  sns.barplot(x='label',y='probability', data=count_L_O_diff_3_pd_new, ax=axes[0][2])
  sns.barplot(x='label',y='probability', data=count_L_O_diff_4_pd_new, ax=axes[0][3])
  sns.barplot(x='label',y='probability', data=count_L_O_diff_5_pd_new, ax=axes[0][4])

  sns.barplot(x='label',y='probability', data=count_M_O_diff_1_pd_new, ax=axes[1][0])
  sns.barplot(x='label',y='probability', data=count_M_O_diff_2_pd_new, ax=axes[1][1])
  sns.barplot(x='label',y='probability', data=count_M_O_diff_3_pd_new, ax=axes[1][2])
  sns.barplot(x='label',y='probability', data=count_M_O_diff_4_pd_new, ax=axes[1][3])
  sns.barplot(x='label',y='probability', data=count_M_O_diff_5_pd_new, ax=axes[1][4])

  sns.barplot(x='label',y='probability', data=count_S_O_diff_1_pd_new, ax=axes[2][0])
  sns.barplot(x='label',y='probability', data=count_S_O_diff_2_pd_new, ax=axes[2][1])
  sns.barplot(x='label',y='probability', data=count_S_O_diff_3_pd_new, ax=axes[2][2])
  sns.barplot(x='label',y='probability', data=count_S_O_diff_4_pd_new, ax=axes[2][3])
  sns.barplot(x='label',y='probability', data=count_S_O_diff_5_pd_new, ax=axes[2][4])

"""
from collections import Counter

count_L_O_1 = Counter(L_O_diff_1_list)
print(count_L_O_1)
count_L_O_diff_1_pd = pd.DataFrame(count_L_O_1.items(),columns=['label', 'counts'])
count_L_O_diff_1_pd['probability']=count_L_O_diff_1_pd['counts']/len(L_O_diff_1_list)


print(count_L_O_diff_1_pd)

print(count_L_O_1[0])
print(count_L_O_1[0] / len(L_O_diff_1_list))
print(count_L_O_1[1])
print(count_L_O_1[1] / len(L_O_diff_1_list))
print(count_L_O_1[2])
print(count_L_O_1[2] / len(L_O_diff_1_list))

"""